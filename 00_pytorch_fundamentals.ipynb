{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e23e7d-915e-460b-9be9-6f91b019cf38",
   "metadata": {},
   "source": [
    "## 00. PyTorch Fundamentals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e372f6-e7c2-47a2-87fd-e6743992fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83407a-3cfe-49f3-acd6-396bfab1d126",
   "metadata": {},
   "source": [
    "## 1. Introduction to Tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "PyTorch tensors are created using `torch.Tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7704262-0f3f-4f1b-9a42-604b83319a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler\n",
    "scaler = torch.tensor(7)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42e5f62-61c1-4d0b-bb71-28f4703a4515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981ef663-d846-40d0-86a2-9bf7f5142c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scaler.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1786a7e3-a326-4bd4-b861-3241e3ab23e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f974dc-ead7-4ecc-ae11-bb8b890597e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df7435c0-8529-4864-afda-9143868925cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b8f4fe-8b5b-4e78-b5b4-6b4dc42ab90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                       [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8894663-419f-4309-95be-b22e4fdd5507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed199d5b-41af-4214-b5a9-60368c05b9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3379b9c-cf21-4d7b-963e-1ef8a48a711d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0452391-0956-46a4-a361-ee44938bc4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b9e407-83d5-48a6-970d-34c4cd9cc962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3856c585-cc06-4936-a28a-d88e709284f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed446dad-0585-4d8d-8384-0018d0bf6f30",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "why random tensors?\n",
    "\n",
    "Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers -> look at data -> update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad576216-5ee6-441e-b8cf-ee3702041b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0476, 0.7762, 0.8493, 0.9022],\n",
       "        [0.3041, 0.8375, 0.4757, 0.1642],\n",
       "        [0.3365, 0.3441, 0.3990, 0.2874]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8ca7063-f5d6-45c4-a7db-e99873f7863d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tesor\n",
    "random_tensor_size_tensor = torch.rand(size=(224,224,3)) # height, width, color channel (R,G,B)\n",
    "random_tensor_size_tensor.shape, random_tensor_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a2d4b-729e-42b1-bfba-463f3bfd843f",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d99dffb8-4541-4b95-9f37-a0fc2f88a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0c4c11-4c38-4929-9beb-8a4d65f2445a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b464a3fa-8dd8-4086-979f-4cec483a9c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ae52a-893b-4122-a540-6925a2009d27",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2d8b10d-5a40-4865-96ec-7515fde6de6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.range()\n",
    "one_to_ten = torch.arange(start=0,end=11,step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14fc2189-9f15-4b12-8bd9-2324101bb134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830741a6-e2bd-4ac5-bedf-4ae89a30703a",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatypte\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce9632e-4755-495c-8d5b-89661ab86c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                               dtype=torch.float32,                    # What datatype is the tensor (e.g float32 or float16)\n",
    "                               device=None,                        # What device is your tensor on\n",
    "                               requires_grad=False)   # Whether or not to track gradients with this tensor operation\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33edeb26-c4b6-4f7d-b519-5266c232733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46785f9f-3f65-42f9-a6fd-9ffc59239867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7da4ccd1-d952-4f82-8ca8-aecdc2b7ab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9],dtype=torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b02bf7c0-f031-4667-82a3-2a17713766e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor*int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5b43ef-9d91-4454-9871-9be334d36c26",
   "metadata": {},
   "source": [
    "### Getting information from tensors\n",
    "\n",
    "1. Tensors not right datatype - to get datatype from a tensor, can use `tensor.dtype`\n",
    "2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape`\n",
    "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d95a8977-d77f-4f96-bd75-0f20714af92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4174, 0.4173, 0.5273, 0.2684],\n",
       "        [0.3020, 0.3288, 0.5193, 0.8731],\n",
       "        [0.7108, 0.8320, 0.7505, 0.1815]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor =torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1a9a6a3-ef1c-4bf0-8b90-0d61dff2bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4174, 0.4173, 0.5273, 0.2684],\n",
      "        [0.3020, 0.3288, 0.5193, 0.8731],\n",
      "        [0.7108, 0.8320, 0.7505, 0.1815]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f'Datatype of tensor: {some_tensor.dtype}')\n",
    "print(f'Shape of tensor: {some_tensor.shape}')\n",
    "print(f'Device of tensor: {some_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a991937-5b73-4ee2-957c-cd3360b03312",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subraction\n",
    "* Multiplication (element-wise)\n",
    "* Division\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "618340c4-cf3d-4f80-98c6-0112167ab72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0ce8b9a-65c7-4e3a-ab9c-84633764827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2f6bd17-b3b2-4c48-bd6d-352a3f3c20cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10\n",
    "tensor - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61149879-2f95-47a0-9a49-b9f5718323e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out PyTorch in-built function\n",
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b41ef6-d891-433f-8a90-aadef9a9d4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e748dd4-a104-46ca-9b3c-a59a1724db1c",
   "metadata": {},
   "source": [
    "### Matrix multiplication\n",
    "\n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix multiplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix multiplication must satify:\n",
    "\n",
    "1. The **inner dimensions** must match:\n",
    "   * `(2,3) @ (2,3) won't work`\n",
    "   * `(3,2) @ (3,2) won't work`\n",
    "   * `(2,3) @ (3,2) will work`\n",
    "   * `(3,2) @ (2,3) will work`\n",
    "   \n",
    "3. The resulting matrix has the shape of the **outer dimensions**:\n",
    "   * `(2,3) @ (3,2) -> (2,2)`\n",
    "   * `(3,2) @ (2,3) -> (3,3)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f9f5c-e1df-41c8-b7a9-5effcea467a1",
   "metadata": {},
   "source": [
    "# Element wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f'Equals: {tensor*tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6933b1a-c2a7-4e65-8609-5ce8aec93551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0cc730e-0feb-4801-8b12-167210c886d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "355cd5ea-174b-4678-a603-224d04c40e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 +2*2+3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f084176-e93f-4784-99f4-c8b5f14052ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value+=tensor[i]*tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "008ba46b-ae30-414d-a653-a5e526229a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)  # tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360fb8fc-0305-40ee-a0c4-6ab0e7ec0201",
   "metadata": {},
   "source": [
    "### One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "922ef8b9-290a-4064-9356-9c6bf5c7a570",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# torch.mm(tensor_A,tensor_B) # torch.mm is the same as torc.matmul( it's a alias for )\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shape for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                        [3,4],\n",
    "                        [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "\n",
    "# torch.mm(tensor_A,tensor_B) # torch.mm is the same as torc.matmul( it's a alias for )\n",
    "torch.matmul(tensor_A,tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feb22326-28d1-4c13-92c3-54a74a583508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15114f9c-7f69-4a83-9808-dce64df6066d",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose.\n",
    "\n",
    "A **transpose** switches the axes or dimensionns of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5f363e0-7f27-4b1e-9be4-fd205075a491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c4e84af-aa08-4880-b60c-303125536ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "893f6490-76ab-4d45-af69-be6015f47f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T=torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimentsionns must match\n",
      "Output:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication operation works when tensor_B is transposed\n",
    "print(f'Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}')\n",
    "print(f'New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T={tensor_B.T.shape}')\n",
    "print(f'Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimentsionns must match')\n",
    "print('Output:\\n')\n",
    "output = torch.mm(tensor_A,tensor_B.T)\n",
    "print(output)\n",
    "print(f'\\noutput shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8da71b9-aa15-4529-a850-9242066f4b43",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum etc (tesor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64bb6d88-95cf-4830-97e5-7482a7df00ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tesor\n",
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "331cace6-5ee5-4953-8c4d-59f35b2516f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2496fc7-42c1-4082-9703-761189e7b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a317159-fea2-4113-a750-a4a24ee2dda5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean - note: thhe torch.mean() function requries a tensor of float32 datatype to work\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "894f8ba5-87b5-4bfb-8070-70f4f093ae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450), tensor(450))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), sum(x),x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50764d5b-af1d-4620-9234-5b7497cfa258",
   "metadata": {},
   "source": [
    "### Find the positional min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f4c2f91-defc-4d64-8539-56cc29c31825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the maximum value with ArgMax\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "007022ec-4cb8-422b-9986-ac01f8ed0074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the minimum value with ArgMin\n",
    "torch.argmin(x), x.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa97bc4-5c2f-40c3-b75f-d6d0c142c1bc",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the orginal tensor\n",
    "* Stacking -- combine multiple tensors on top of each other(vstack) or side by side (hstack)\n",
    "* Squeeze - remmoves all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute- Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "44646760-b9f0-4128-8f62-67d2bc5bd5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "aecd5ca6-6e29-44c7-a7f3-3b3a66bd7df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca2e7ff4-a483-42b8-baab-3f819b13d29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1,9)\n",
    "z,z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89ca2380-acff-4210-b978-48dac1c56073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing z changes x (because a view of a tensor shares the same memory as the original inputs )\n",
    "z[:,0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29152086-d249-4b3e-a528-24b58993bf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x],dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f5651a0-47dd-468d-9f97-2d41986b653e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - remove all single dimensions from a target tensor\n",
    "print(f'Previous tensor: {x_reshaped}')\n",
    "print(f'Previous shape: {x_reshaped.shape}')\n",
    "\n",
    "# Remove extra dimensions from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f'\\nNew tensor: {x_squeezed}')\n",
    "print(f'New shape: {x_squeezed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f9ac3369-4f89-49a1-bcd5-1876e7b5da71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueez() - adds a single dimension to a target tensor at a specific dim (dimensions))\n",
    "print(f'Previous target: {x_squeezed}')\n",
    "print(f'Previous shape: {x_squeezed.shape}')\n",
    "\n",
    "# Add an extra dimension with usqeezed\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f'\\nNew tensor: {x_unsqueezed}')\n",
    "print(f'New shape: {x_unsqueezed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d75e91ff-1d10-4177-8058-e6c0e5e506c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of target tensors in a specific order\n",
    "x_original = torch.rand(size=(224,224,3)) # height, width, color_channels\n",
    "\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2,0,1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f'Previous shape: {x_original.shape}')\n",
    "print(f'New shape: {x_permuted.shape}')  # colour_channel, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5f4c46a4-cd44-49d4-b0a5-b84c91d97bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2971, 0.2104, 0.2237],\n",
       "         [0.2855, 0.8040, 0.2371],\n",
       "         [0.2659, 0.1217, 0.3877],\n",
       "         ...,\n",
       "         [0.9398, 0.9395, 0.3284],\n",
       "         [0.3858, 0.5533, 0.1495],\n",
       "         [0.3001, 0.7297, 0.7672]],\n",
       "\n",
       "        [[0.6561, 0.1547, 0.8571],\n",
       "         [0.4162, 0.8224, 0.7521],\n",
       "         [0.2451, 0.3889, 0.3319],\n",
       "         ...,\n",
       "         [0.6996, 0.2326, 0.1175],\n",
       "         [0.7899, 0.4512, 0.8447],\n",
       "         [0.3771, 0.7290, 0.2998]],\n",
       "\n",
       "        [[0.4581, 0.5118, 0.5146],\n",
       "         [0.1405, 0.3973, 0.5485],\n",
       "         [0.8166, 0.6657, 0.4521],\n",
       "         ...,\n",
       "         [0.1911, 0.5159, 0.7699],\n",
       "         [0.9745, 0.5348, 0.3566],\n",
       "         [0.2191, 0.6788, 0.6509]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7146, 0.9919, 0.0857],\n",
       "         [0.8300, 0.8110, 0.5281],\n",
       "         [0.9985, 0.9445, 0.0931],\n",
       "         ...,\n",
       "         [0.9451, 0.2687, 0.6333],\n",
       "         [0.6904, 0.1051, 0.0975],\n",
       "         [0.3974, 0.7046, 0.2742]],\n",
       "\n",
       "        [[0.5233, 0.4211, 0.5313],\n",
       "         [0.4804, 0.8216, 0.8569],\n",
       "         [0.5049, 0.6274, 0.3474],\n",
       "         ...,\n",
       "         [0.4064, 0.3929, 0.0194],\n",
       "         [0.2473, 0.0450, 0.6942],\n",
       "         [0.3115, 0.1402, 0.4330]],\n",
       "\n",
       "        [[0.3354, 0.6826, 0.9425],\n",
       "         [0.8808, 0.2732, 0.1871],\n",
       "         [0.0559, 0.7243, 0.2260],\n",
       "         ...,\n",
       "         [0.7711, 0.9239, 0.0023],\n",
       "         [0.2079, 0.5407, 0.3868],\n",
       "         [0.3112, 0.4501, 0.4223]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1fe1a60-30a8-4489-9c77-91ed6c2df807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2971, 0.2855, 0.2659,  ..., 0.9398, 0.3858, 0.3001],\n",
       "         [0.6561, 0.4162, 0.2451,  ..., 0.6996, 0.7899, 0.3771],\n",
       "         [0.4581, 0.1405, 0.8166,  ..., 0.1911, 0.9745, 0.2191],\n",
       "         ...,\n",
       "         [0.7146, 0.8300, 0.9985,  ..., 0.9451, 0.6904, 0.3974],\n",
       "         [0.5233, 0.4804, 0.5049,  ..., 0.4064, 0.2473, 0.3115],\n",
       "         [0.3354, 0.8808, 0.0559,  ..., 0.7711, 0.2079, 0.3112]],\n",
       "\n",
       "        [[0.2104, 0.8040, 0.1217,  ..., 0.9395, 0.5533, 0.7297],\n",
       "         [0.1547, 0.8224, 0.3889,  ..., 0.2326, 0.4512, 0.7290],\n",
       "         [0.5118, 0.3973, 0.6657,  ..., 0.5159, 0.5348, 0.6788],\n",
       "         ...,\n",
       "         [0.9919, 0.8110, 0.9445,  ..., 0.2687, 0.1051, 0.7046],\n",
       "         [0.4211, 0.8216, 0.6274,  ..., 0.3929, 0.0450, 0.1402],\n",
       "         [0.6826, 0.2732, 0.7243,  ..., 0.9239, 0.5407, 0.4501]],\n",
       "\n",
       "        [[0.2237, 0.2371, 0.3877,  ..., 0.3284, 0.1495, 0.7672],\n",
       "         [0.8571, 0.7521, 0.3319,  ..., 0.1175, 0.8447, 0.2998],\n",
       "         [0.5146, 0.5485, 0.4521,  ..., 0.7699, 0.3566, 0.6509],\n",
       "         ...,\n",
       "         [0.0857, 0.5281, 0.0931,  ..., 0.6333, 0.0975, 0.2742],\n",
       "         [0.5313, 0.8569, 0.3474,  ..., 0.0194, 0.6942, 0.4330],\n",
       "         [0.9425, 0.1871, 0.2260,  ..., 0.0023, 0.3868, 0.4223]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "26d970d5-44fc-41e7-aabc-ceb858e52865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(72434344.), tensor(72434344.))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0,0,0] = 72434343\n",
    "x_original[0,0,0], x_permuted[0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d6e091-2200-4db0-834a-cb6629507a72",
   "metadata": {},
   "source": [
    "### Indexing with PyTorch is similar to indexing with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e3e5c10a-86c0-494a-acfb-93f6f4a4457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "425f1a4f-7b73-4325-98c6-8940fd88fe92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c597e66b-2ca7-4862-929a-e8f51df40ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the middle bracket (dim=1)\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "974ce668-f848-42c9-82e2-486c72a636ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (last dimension)\n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45a1f8dc-76bc-4af1-a7f7-56bffb10f349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "103ec72e-a411-40f5-a32c-52e648c90659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e3fe122-1afe-4d91-a149-d9ed8dcbf8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0th dimension but only the 1 index value of 1st and 2nd dimesnion\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70ff4410-8429-4ade-8aa9-cddb42b185bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimensio\n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1bc66f49-8d2b-4465-ba33-9c5951c2c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "print(x[0][2][2])\n",
    "\n",
    "# index on x to return 3,6,9\n",
    "print(x[:,:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9aaee-eb40-488b-9a6a-64ead3eecb4a",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python nummerical computing library.\n",
    "\n",
    "And because of this, PyTorch hahs functionality to interact with it.\n",
    "\n",
    "* Data is Numpy, want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor ->Numpy-> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d1fd800e-77cf-4bb4-9ba7-8e4dc8e3eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "array= np.arange(1.0,8.)\n",
    "tensor = torch.from_numpy(array)   # warning: when converting from numpy -> pytorch, pytorch relexts numpy's default dtype\n",
    "array,tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2ac0e6d8-bb85-4e58-adee-316ce2f4eb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change theh value of array, what will this do to `tensor`?\n",
    "array = array +1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e8adf8f-97ea-404d-af3d-e52e9780c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to p array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0dd035b2-4104-4a4e-87e5-93d13a8fd65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to `numpy_tensor`?\n",
    "tensor = tensor +1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675c49e-db1d-4db4-b385-23781cc85d31",
   "metadata": {},
   "source": [
    "## Reproducbility (trying to take random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "`start with random numbers` -> tensor operatons -> update random numbers to try and make them better representations of the data -> again -> angain -> again...\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**.\n",
    "Essentially what the random seed does is 'flavor' the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43b3041b-4f0e-4371-9914-96f2506c3a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0252, 0.1422, 0.5692, 0.5167],\n",
      "        [0.5081, 0.1480, 0.9136, 0.8561],\n",
      "        [0.8801, 0.5568, 0.6583, 0.0235]])\n",
      "tensor([[0.6993, 0.9372, 0.1089, 0.7880],\n",
      "        [0.3007, 0.5925, 0.8197, 0.8035],\n",
      "        [0.7321, 0.9269, 0.5969, 0.5432]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# create two random tensors\n",
    "random_tensor_A = torch.rand(3,4)\n",
    "random_tensor_B = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A==random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a2f20f2-ec41-437e-9eee-9c597af85dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors\n",
    "\n",
    "# Set the random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C==random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bfa491-7575-402f-8bdf-090ca46ad093",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on the GPUs ( and making faster computations)\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky\n",
    "dory (good)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5249d-c0e6-41ff-a668-ab57f1861671",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "\n",
    "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "2. Use you own GPU - takes a little bit o setup and requires the investment of purchassing a GPU, there's lots of options...\n",
    "3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them.\n",
    "\n",
    "For 2,3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documentation: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbd9b5b-2274-4196-8f03-cc2384dcc198",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1277fa25-1c5b-4020-ad34-9e814565985d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for GPU access with pyTorch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f23f4f4a-5e21-47fe-9719-1f1cb4627cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "56324808-8ea2-42c4-a19c-df480526e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfee9a0-525e-4e19-bd38-edfaa6cdaba8",
   "metadata": {},
   "source": [
    "## 3. Putting tensors  (and models) on theh GPU\n",
    "\n",
    "The reason we wnant our tensors/models on the GPU is because using a GPU results in faster computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e05b724-550d-4793-becc-8270d4c21cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on the CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor,tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "10985fe6-7c1e-4774-80c2-7d0a9d146943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90725e50-2b52-48f4-94c8-af210f6151a4",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6672aac6-87dc-4b03-b43b-b83c81c0cdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transfor it to NumPy\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "96b2c26d-4c35-434d-9628-ea1a1d7f5aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53f7437f-e80e-473c-9a60-8c03f1691b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84fdcf-233d-43b7-af70-9f6eecada5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692711c-0c19-455f-97cb-4ca3e70c12ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00071857-3591-403a-a832-bd361b50ec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e1415-4875-414d-b526-05e2e4b37ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b534fe-4c53-407c-947c-f48833c368f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
